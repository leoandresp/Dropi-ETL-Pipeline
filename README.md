# ‚öôÔ∏è ELT Dropi Data Pipeline - Integraci√≥n y Verificaci√≥n de √ìrdenes üìä

Este proyecto implementa un **ELT** (Extract, Load, Transform) para la consolidaci√≥n de reportes de la plataforma **Dropi**. Utiliza una soluci√≥n de **RPA** para la descarga automatizada de reportes y un *pipeline* de procesamiento de datos en capas **Raw**, **Silver** y **Gold**.

---

## üöÄ Objetivo Principal

El prop√≥sito central del *pipeline* es **consolidar y evaluar la trazabilidad y la liquidaci√≥n financiera** de cada orden. El objetivo final es generar un archivo maestro √∫nico que permita:

1.  Determinar el **estado real** y la **trazabilidad completa** de cada orden.
2.  Calcular el **monto neto pagado** (entradas menos salidas) por orden.
3.  Verificar si la **liquidaci√≥n** (el pago final) fue correcta, especialmente en el caso de las √≥rdenes **entregadas** y **devueltas**.

---

## üõ†Ô∏è Flujo del Proceso (ELT)

El proceso se divide en la ingesta, limpieza y transformaci√≥n, siguiendo una arquitectura de capas de datos:

### 1. Extracci√≥n y Carga (E & L) - Capa **Raw**

* **RPA:** Una herramienta de automatizaci√≥n rob√≥tica accede a la cuenta de **Dropi** y descarga los siguientes reportes diarios:
    * √ìrdenes
    * Devoluciones
    * Garant√≠as
    * Historial de Cartera
* **Carga:** Los reportes descargados se cargan directamente a la capa **Raw** (datos sin procesar).

### 2. Transformaci√≥n I - Capa **Silver**

Esta capa se enfoca en la **limpieza** y **preparaci√≥n** de los datos antes de la consolidaci√≥n.

* Se realiza la **limpieza de espacios en blanco** en los campos de texto.
* Los reportes acumulativos (ej. Historial de Cartera) se actualizan **fusionando** el archivo m√°s reciente con el hist√≥rico, asegurando que **no haya duplicidad** de informaci√≥n y manteniendo solo el registro m√°s antiguo hasta la fecha del nuevo reporte.

### 3. Transformaci√≥n II - Capa **Gold** (Consolidaci√≥n)

Esta es la capa final donde se aplica la l√≥gica de negocio para generar el archivo maestro consolidado, uniendo toda la informaci√≥n.

* **Inicio con √ìrdenes:** La lista de √≥rdenes sirve como punto de partida. Se **estandarizan los estados** de la orden (ej., 'Completada' y 'Finalizada' se unifican).
* **A√±adir Garant√≠as:** Se agrupan y se a√±aden todos los **c√≥digos de garant√≠a** asociados a cada orden en una sola celda.
* **A√±adir Historial de Pagos:** Se determina la **fecha m√°s reciente** de pago y se calcula el **monto total pagado neto** (sumando 'Entradas' y restando 'Salidas').
* **A√±adir Devoluciones:** Se registra la fecha y el ID del registro de devoluci√≥n si aplica.
* **Chequeo de Verificaci√≥n (Liquidaci√≥n):** Se aplica una l√≥gica de negocio para evaluar la liquidaci√≥n:
    * Si la orden est√° **ENTREGADA**, se compara el monto esperado *versus* el monto pagado. Si coinciden, es **"OK"**, si no **"POR REVISAR"**.
    * Si la orden est√° **DEVUELTA**, se valida la existencia de la fecha de devoluci√≥n. Si existe, es **"OK"**, si no **"POR REVISAR"**.

* **Mantenimiento de la Base Maestra:** El *dataframe* consolidado se utiliza para actualizar el archivo maestro final:
    * Se a√±aden las **√≥rdenes nuevas**.
    * Se actualizan los datos de las **√≥rdenes existentes**.
    * Se mantiene un **historial de estados** para cada orden, registrando la fecha del √∫ltimo cambio de estado.

---

## ‚ö†Ô∏è Estado del Proyecto

Este proyecto **no est√° completamente finalizado** y se encuentra en fase de desarrollo activo.

### üìå Tareas Pendientes:

* Validar que la actualizaci√≥n de las columnas de **fecha y hora (*timestamp*)** sea correcta.
* Incluir el campo **`update_at`** en la informaci√≥n general de ventas.
* **Validar** que las rutas de archivos funcionen correctamente en un entorno **Linux**.
* Implementar el **Monitoreo de Logging** y los **Logs de inserci√≥n** completos.
