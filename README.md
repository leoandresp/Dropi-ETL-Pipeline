# Automatizaci√≥n Dropi - Pipeline ETL

## üìã Descripci√≥n

Este proyecto es un sistema automatizado de extracci√≥n, transformaci√≥n y carga (ETL) que obtiene datos de la plataforma **Dropi** (plataforma de e-commerce) mediante web scraping, los procesa en un pipeline de tres capas (Bronze, Silver, Gold) y los almacena en una base de datos DuckDB para generar reportes de ventas generales.

### Funcionalidad Principal

El sistema automatiza la extracci√≥n de los siguientes datos desde Dropi:
- **√ìrdenes** (una orden por fila y √≥rdenes con productos)
- **Garant√≠as**
- **Historial de Cartera**
- **Devoluciones**

Posteriormente, procesa estos datos a trav√©s de un pipeline de tres capas:
1. **Bronze (Capa Raw)**: Almacena los datos extra√≠dos sin procesar
2. **Silver (Capa Limpia)**: Limpia y transforma los datos raw
3. **Gold (Capa Final)**: Genera agregaciones y reportes finales

El resultado final es un archivo CSV (`general_sales.csv`) con un reporte consolidado de ventas generales.

## üöÄ Requisitos Previos

- **Python 3.12** o superior
- **Navegador Chrome** instalado (para Selenium)
- **Cuenta de Dropi** con credenciales de acceso
- **Conexi√≥n a Internet** (para acceder a Dropi y descargar datos)

## üì¶ Instalaci√≥n

### 1. Clonar o descargar el proyecto

```bash
cd DROPO_ETL_Pipeline
```

### 2. Crear y activar el entorno virtual

**En Windows:**
```bash
python -m venv dropi-extractor-venv
dropi-extractor-venv\Scripts\activate
```

**En Linux/Mac:**
```bash
python3 -m venv dropi-extractor-venv
source dropi-extractor-venv/bin/activate
```

### 3. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar variables de entorno

Crear un archivo `.env` en la ra√≠z del proyecto con las siguientes variables:

```env
DROPI_USER=tu_usuario_dropi
DROPI_PASS=tu_contrase√±a_dropi
DROPI_SHEETS_ID=id_de_google_sheets_opcional
```

**Nota**: El archivo `.env` no debe subirse al repositorio por seguridad.

### 5. Verificar archivos necesarios

Aseg√∫rate de que exista el archivo de credenciales de Google Sheets (si se requiere):
- `assets/anakarinadropi-572e7897ef4c.json`

## ‚ñ∂Ô∏è Ejecuci√≥n

### ‚ö†Ô∏è Primera Ejecuci√≥n - Inicializaci√≥n Autom√°tica

**Si es la primera vez que ejecutas el proyecto**, el sistema realizar√° autom√°ticamente:

1. **Creaci√≥n de la base de datos**: Se crear√° autom√°ticamente el archivo `db/Oferfly.duckdb` en la carpeta `db/`
2. **Creaci√≥n de todas las tablas**: Se ejecutar√° el script de inicializaci√≥n (`db/init_tables.py`) que crear√° todas las tablas necesarias:
   - **Tablas RAW (Bronze)**: `RAW_ORDERS`, `RAW_ORDERS_PRODUCTS`, `RAW_WARRANTYS`, `RAW_WALLET`, `RAW_DEVOLUTIONS`
   - **Tablas finales (Silver/Gold)**: `ORDERS`, `ORDERS_PRODUCT`, `WARRANTYS`, `WALLET`, `DEVOLUTIONS`, `GENERAL_SALES`

**Nota importante**: 
- La inicializaci√≥n es autom√°tica y se ejecuta cada vez que corres el pipeline
- Solo crea las tablas que no existen, por lo que es seguro ejecutarlo m√∫ltiples veces
- Si alguna tabla ya existe, el sistema la detectar√° y no la recrear√°
- Los logs mostrar√°n qu√© tablas se crearon y cu√°les ya exist√≠an

### Ejecutar el pipeline completo

Desde la ra√≠z del proyecto, ejecutar:

```bash
python main.py
```

El script ejecutar√° autom√°ticamente los tres pasos del pipeline:
1. `pipeline.run_bronze_pipeline` - Extracci√≥n y carga de datos raw
2. `pipeline.run_silver_pipeline` - Transformaci√≥n y limpieza de datos
3. `pipeline.run_gold_pipeline` - Generaci√≥n del reporte final

### Salida esperada

Al finalizar la ejecuci√≥n, encontrar√°s:
- **Base de datos**: `db/Oferfly.duckdb` (DuckDB con todas las tablas procesadas - se crea autom√°ticamente en la primera ejecuci√≥n)
- **Reporte CSV**: `data/general_sales.csv` (reporte final de ventas generales)

## üìÅ Estructura del Proyecto

```
NUEVA_Automatizacion_Dropi/
‚îú‚îÄ‚îÄ assets/                    # Archivos de configuraci√≥n (credenciales Google Sheets)
‚îú‚îÄ‚îÄ data/                      # Datos de salida (CSV generados)
‚îú‚îÄ‚îÄ db/                        # Base de datos DuckDB y queries SQL
‚îÇ   ‚îú‚îÄ‚îÄ querys/               # Scripts SQL para crear tablas y upserts
‚îÇ   ‚îú‚îÄ‚îÄ init_tables.py         # Script de inicializaci√≥n de tablas (se ejecuta autom√°ticamente)
‚îÇ   ‚îî‚îÄ‚îÄ Oferfly.duckdb        # Base de datos (se crea autom√°ticamente)
‚îú‚îÄ‚îÄ dropi_logic/              # L√≥gica de extracci√≥n (RPA, scraping, Google Sheets)
‚îú‚îÄ‚îÄ pipeline/                 # Pipeline ETL (extract, transform, load)
‚îú‚îÄ‚îÄ validations/              # Validaciones de datos
‚îú‚îÄ‚îÄ config.py                 # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ main.py                   # Punto de entrada principal
‚îú‚îÄ‚îÄ requirements.txt          # Dependencias del proyecto
‚îî‚îÄ‚îÄ .env                      # Variables de entorno (crear manualmente)
```

## üîÑ Flujo del Pipeline

### 1. Bronze Pipeline
- **Extracci√≥n**: Utiliza Selenium para hacer web scraping en Dropi y descargar reportes Excel
- **Carga**: Almacena los datos sin procesar en tablas RAW (RAW_ORDERS, RAW_ORDERS_PRODUCTS, RAW_WARRANTYS, RAW_WALLET, RAW_DEVOLUTIONS)

### 2. Silver Pipeline
- **Extracci√≥n**: Obtiene los datos de la √∫ltima ingesta de la capa Bronze
- **Transformaci√≥n**: 
  - Limpia y valida los datos
  - Normaliza formatos de fechas
  - Transforma estados de √≥rdenes
  - Separa campos compuestos
- **Carga**: Almacena datos procesados en tablas finales (ORDERS, ORDERS_PRODUCT, WARRANTYS, WALLET, DEVOLUTIONS)

### 3. Gold Pipeline
- **Extracci√≥n**: Obtiene datos agregados de la capa Silver
- **Validaci√≥n**: Valida datos num√©ricos y nulos
- **Carga**: Genera tabla consolidada GENERAL_SALES y exporta a CSV

## ‚öôÔ∏è Configuraci√≥n

El archivo `config.py` contiene toda la configuraci√≥n del proyecto:
- Rutas de directorios
- Configuraci√≥n de base de datos
- Tipos de datos para DataFrames
- Mapeo de estados de √≥rdenes
- Configuraci√≥n de scraping y Google Sheets

## üìä Tablas de la Base de Datos

### Capa Bronze (RAW)
- `RAW_ORDERS`
- `RAW_ORDERS_PRODUCTS`
- `RAW_WARRANTYS`
- `RAW_WALLET`
- `RAW_DEVOLUTIONS`

### Capa Silver/Gold
- `ORDERS`
- `ORDERS_PRODUCT`
- `WARRANTYS`
- `WALLET`
- `DEVOLUTIONS`
- `GENERAL_SALES`

## üîç Logs

El sistema genera logs detallados durante la ejecuci√≥n con el siguiente formato:
```
YYYY-MM-DD HH:MM:SS - LEVEL - Mensaje
```

Los logs incluyen informaci√≥n sobre:
- Inicio y fin de cada paso del pipeline
- Errores y advertencias
- Progreso de descargas y procesamiento

## ‚ö†Ô∏è Notas Importantes

1. **Tiempo de ejecuci√≥n**: El proceso completo puede tardar varios minutos debido a:
   - Web scraping (requiere esperar descargas de archivos Excel)
   - Procesamiento de datos
   - Validaciones

2. **Navegador**: El sistema utiliza Chrome con Selenium. Aseg√∫rate de tener Chrome instalado y actualizado.

3. **Carpeta de Descargas**: Los archivos Excel se descargan temporalmente en la carpeta `Downloads` del usuario y luego se procesan.

4. **Base de Datos**: La base de datos DuckDB (`db/Oferfly.duckdb`) y todas las tablas se crean autom√°ticamente en la primera ejecuci√≥n mediante el script `db/init_tables.py`. No es necesario crear manualmente la base de datos ni las tablas.

## üêõ Soluci√≥n de Problemas

### Error: "El ejecutable de Python no fue encontrado"
- Verifica que el entorno virtual est√© creado correctamente
- Aseg√∫rate de que el nombre del venv sea `dropi-extractor-venv`

### Error: "Variables de entorno no encontradas"
- Verifica que el archivo `.env` exista en la ra√≠z del proyecto
- Confirma que las variables `DROPI_USER` y `DROPI_PASS` est√©n configuradas

### Error: "ChromeDriver no encontrado"
- El proyecto usa `webdriver-manager` que descarga autom√°ticamente el driver
- Verifica tu conexi√≥n a Internet

### Error en la descarga de archivos
- Verifica tu conexi√≥n a Internet
- Confirma que las credenciales de Dropi sean correctas
- Revisa que la carpeta `Downloads` sea accesible

## üìù Dependencias Principales

- **selenium**: Web scraping automatizado
- **pandas**: Procesamiento de datos
- **duckdb**: Base de datos anal√≠tica
- **openpyxl**: Lectura de archivos Excel
- **python-dotenv**: Gesti√≥n de variables de entorno
- **google-api-python-client**: Integraci√≥n con Google Sheets (opcional)

## üë§ Autor

Proyecto desarrollado por Leonardo Polanco


